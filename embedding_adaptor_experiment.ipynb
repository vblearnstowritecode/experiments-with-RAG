{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "experiment-intro",
   "metadata": {},
   "source": [
    "# TCS Embedding Adaptor Learning Experiment\n",
    "\n",
    "## Goal: Learn Domain-Specific Embedding Adaptation\n",
    "\n",
    "This experiment explores whether a simple transformation matrix can improve retrieval for TCS-specific queries.\n",
    "\n",
    "**Key Learning Question**: Does adapting query embeddings help with domain-specific language?\n",
    "\n",
    "## The Concept\n",
    "- **Problem**: General embeddings may not capture TCS-specific relationships\n",
    "- **Solution**: Learn a matrix that transforms queries: `adapted_query = matrix √ó original_query`\n",
    "- **Learning**: Understanding parameter-efficient adaptation (like LoRA for retrieval)\n",
    "\n",
    "## Experiment Flow\n",
    "1. Generate 20 training + 20 test questions\n",
    "2. Create training data with GPT-4.1 relevance labeling\n",
    "3. Train simple 384√ó384 transformation matrix\n",
    "4. Compare Simple RAG vs Adapted RAG\n",
    "5. Analyze what we learned about domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Trying\\25September2025\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "üéØ Ready to start embedding adaptation experiment\n"
     ]
    }
   ],
   "source": [
    "# Setup and Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(\"üéØ Ready to start embedding adaptation experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "connect-chromadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÉÔ∏è  Connecting to ChromaDB at ./chroma_db...\n",
      "‚úÖ Connected to collection: tcs_annual_report_2024\n",
      "üìä Total document chunks: 1,324\n",
      "ü§ñ Embedding model loaded: 384 dimensions\n",
      "\n",
      "üöÄ Ready for embedding adaptation experiment!\n"
     ]
    }
   ],
   "source": [
    "# Connect to Existing ChromaDB Collection\n",
    "CHROMA_DB_PATH = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"tcs_annual_report_2024\"\n",
    "\n",
    "print(f\"üóÉÔ∏è  Connecting to ChromaDB at {CHROMA_DB_PATH}...\")\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "\n",
    "# Get existing collection\n",
    "chroma_collection = chroma_client.get_collection(\n",
    "    COLLECTION_NAME,\n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "# Verify collection\n",
    "count = chroma_collection.count()\n",
    "print(f\"‚úÖ Connected to collection: {COLLECTION_NAME}\")\n",
    "print(f\"üìä Total document chunks: {count:,}\")\n",
    "\n",
    "# Initialize SentenceTransformer model (same as ChromaDB)\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"ü§ñ Embedding model loaded: {embedding_model.get_sentence_embedding_dimension()} dimensions\")\n",
    "\n",
    "print(\"\\nüöÄ Ready for embedding adaptation experiment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-header",
   "metadata": {},
   "source": [
    "# Step 1: Generate Training and Test Questions\n",
    "\n",
    "We'll create 40 questions total:\n",
    "- 20 training questions focusing on TCS-specific terminology\n",
    "- 20 test questions for comparison\n",
    "\n",
    "Focus on terms that general embeddings might struggle with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "training-questions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Generated 20 training questions\n",
      "\n",
      "Sample training questions:\n",
      "1. What are the key features of TCS WisdomNext platform?\n",
      "2. How does TCS Pace Port accelerate innovation for clients?\n",
      "3. What is the role of TCS Co-innovation Network in client transformation?\n",
      "...\n",
      "\n",
      "‚úÖ Training questions ready: 20 TCS-specific questions\n"
     ]
    }
   ],
   "source": [
    "# Training Questions (20) - TCS-Specific Terms and Concepts\n",
    "training_questions = [\n",
    "    \"What are the key features of TCS WisdomNext platform?\",\n",
    "    \"How does TCS Pace Port accelerate innovation for clients?\",\n",
    "    \"What is the role of TCS Co-innovation Network in client transformation?\",\n",
    "    \"How does TCS BaNCS support banking operations?\",\n",
    "    \"What capabilities does TCS Crystallus offer for telecommunications?\",\n",
    "    \"How does TCS OptumeraTM enhance retail operations?\",\n",
    "    \"What is the purpose of TCS OmniStore platform?\",\n",
    "    \"How does TCS ignioTM transform IT operations?\",\n",
    "    \"What role does TCS Clever Energy play in sustainability?\",\n",
    "    \"How does TCS MasterCraft support software engineering?\",\n",
    "    \"What is the function of TCS TwinX in digital transformation?\",\n",
    "    \"How does TCS InTwin enable simulable enterprises?\",\n",
    "    \"What services does TCS iON provide for learning ecosystems?\",\n",
    "    \"How does TCS ADD platform support clinical trials?\",\n",
    "    \"What is the impact of TCS CodeVita programming contest?\",\n",
    "    \"How does TCS Bringing Life to Things Lab drive IoT innovation?\",\n",
    "    \"What is the significance of TCS Quantum Diamond Microchip collaboration?\",\n",
    "    \"How does TCS support the National Quantum Mission initiative?\",\n",
    "    \"What role does TCS Pace Studio play in regional innovation?\",\n",
    "    \"How does TCS All-women Digital Services Center empower talent?\"\n",
    "]\n",
    "\n",
    "print(f\"üìã Generated {len(training_questions)} training questions\")\n",
    "print(\"\\nSample training questions:\")\n",
    "for i, q in enumerate(training_questions[:3], 1):\n",
    "    print(f\"{i}. {q}\")\n",
    "print(\"...\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training questions ready: {len(training_questions)} TCS-specific questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "test-questions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Generated 20 test questions\n",
      "\n",
      "Sample test questions:\n",
      "1. What are TCS's main research and development priorities?\n",
      "2. How does TCS approach digital transformation for manufacturing clients?\n",
      "3. What is TCS's strategy for artificial intelligence implementation?\n",
      "...\n",
      "\n",
      "‚úÖ Test questions ready: 20 questions for comparison\n",
      "\n",
      "üéØ Total questions generated: 40\n"
     ]
    }
   ],
   "source": [
    "# Test Questions (20) - Different TCS Topics for Comparison\n",
    "test_questions = [\n",
    "    \"What are TCS's main research and development priorities?\",\n",
    "    \"How does TCS approach digital transformation for manufacturing clients?\",\n",
    "    \"What is TCS's strategy for artificial intelligence implementation?\",\n",
    "    \"How does TCS support clients in cloud migration initiatives?\",\n",
    "    \"What role does TCS play in cybersecurity solutions?\",\n",
    "    \"How does TCS contribute to sustainability and green energy initiatives?\",\n",
    "    \"What is TCS's approach to talent development and reskilling?\",\n",
    "    \"How does TCS support government digital transformation projects?\",\n",
    "    \"What are TCS's key partnerships with technology vendors?\",\n",
    "    \"How does TCS approach innovation in financial services?\",\n",
    "    \"What is TCS's methodology for enterprise modernization?\",\n",
    "    \"How does TCS support healthcare and life sciences digitization?\",\n",
    "    \"What are TCS's capabilities in data analytics and insights?\",\n",
    "    \"How does TCS approach automation in business operations?\",\n",
    "    \"What role does TCS play in telecommunications modernization?\",\n",
    "    \"How does TCS support retail and consumer business transformation?\",\n",
    "    \"What is TCS's approach to regulatory compliance solutions?\",\n",
    "    \"How does TCS enable supply chain optimization for clients?\",\n",
    "    \"What are TCS's key differentiators in the IT services market?\",\n",
    "    \"How does TCS measure and ensure client satisfaction?\"\n",
    "]\n",
    "\n",
    "print(f\"üìã Generated {len(test_questions)} test questions\")\n",
    "print(\"\\nSample test questions:\")\n",
    "for i, q in enumerate(test_questions[:3], 1):\n",
    "    print(f\"{i}. {q}\")\n",
    "print(\"...\")\n",
    "\n",
    "print(f\"\\n‚úÖ Test questions ready: {len(test_questions)} questions for comparison\")\n",
    "print(f\"\\nüéØ Total questions generated: {len(training_questions) + len(test_questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-header",
   "metadata": {},
   "source": [
    "# Step 2: Create Training Data\n",
    "\n",
    "For each training question:\n",
    "1. Retrieve top 10 chunks from ChromaDB\n",
    "2. Use GPT-4.1 to label each (query, chunk) pair as relevant/irrelevant\n",
    "3. Build training dataset of ~200 labeled examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "retrieve-chunks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Retrieving chunks for training questions...\n",
      "Retrieving for Q1/20: What are the key features of TCS WisdomNext platfo...\n",
      "Retrieving for Q2/20: How does TCS Pace Port accelerate innovation for c...\n",
      "Retrieving for Q3/20: What is the role of TCS Co-innovation Network in c...\n",
      "Retrieving for Q4/20: How does TCS BaNCS support banking operations?...\n",
      "Retrieving for Q5/20: What capabilities does TCS Crystallus offer for te...\n",
      "Retrieving for Q6/20: How does TCS OptumeraTM enhance retail operations?...\n",
      "Retrieving for Q7/20: What is the purpose of TCS OmniStore platform?...\n",
      "Retrieving for Q8/20: How does TCS ignioTM transform IT operations?...\n",
      "Retrieving for Q9/20: What role does TCS Clever Energy play in sustainab...\n",
      "Retrieving for Q10/20: How does TCS MasterCraft support software engineer...\n",
      "Retrieving for Q11/20: What is the function of TCS TwinX in digital trans...\n",
      "Retrieving for Q12/20: How does TCS InTwin enable simulable enterprises?...\n",
      "Retrieving for Q13/20: What services does TCS iON provide for learning ec...\n",
      "Retrieving for Q14/20: How does TCS ADD platform support clinical trials?...\n",
      "Retrieving for Q15/20: What is the impact of TCS CodeVita programming con...\n",
      "Retrieving for Q16/20: How does TCS Bringing Life to Things Lab drive IoT...\n",
      "Retrieving for Q17/20: What is the significance of TCS Quantum Diamond Mi...\n",
      "Retrieving for Q18/20: How does TCS support the National Quantum Mission ...\n",
      "Retrieving for Q19/20: What role does TCS Pace Studio play in regional in...\n",
      "Retrieving for Q20/20: How does TCS All-women Digital Services Center emp...\n",
      "\n",
      "‚úÖ Retrieved chunks for 20 questions\n",
      "üìä Total (question, chunk) pairs: 200\n",
      "\n",
      "üéØ Ready for relevance labeling with GPT-4.1\n"
     ]
    }
   ],
   "source": [
    "# Retrieve Chunks for Training Questions\n",
    "def retrieve_chunks_for_question(question, collection, n_results=10):\n",
    "    \"\"\"Retrieve top chunks for a question from ChromaDB\"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'question': question,\n",
    "        'chunks': results['documents'][0],\n",
    "        'distances': results['distances'][0],\n",
    "        'ids': results['ids'][0]\n",
    "    }\n",
    "\n",
    "print(\"üîç Retrieving chunks for training questions...\")\n",
    "\n",
    "# Retrieve chunks for all training questions\n",
    "training_data_raw = []\n",
    "\n",
    "for i, question in enumerate(training_questions, 1):\n",
    "    print(f\"Retrieving for Q{i}/20: {question[:50]}...\")\n",
    "    \n",
    "    result = retrieve_chunks_for_question(question, chroma_collection, n_results=10)\n",
    "    training_data_raw.append(result)\n",
    "\n",
    "print(f\"\\n‚úÖ Retrieved chunks for {len(training_data_raw)} questions\")\n",
    "\n",
    "# Calculate total training pairs\n",
    "total_pairs = sum(len(item['chunks']) for item in training_data_raw)\n",
    "print(f\"üìä Total (question, chunk) pairs: {total_pairs}\")\n",
    "\n",
    "print(\"\\nüéØ Ready for relevance labeling with GPT-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "label-relevance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Starting relevance labeling with GPT-4.1...\n",
      "This will take a few minutes...\n",
      "\n",
      "Labeling Q1/20: What are the key features of TCS WisdomN...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 1\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 1\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q2/20: How does TCS Pace Port accelerate innova...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 1\n",
      "  Chunk 3/10... Label: 1\n",
      "  Chunk 4/10... Label: 1\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 1\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q3/20: What is the role of TCS Co-innovation Ne...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 0\n",
      "  Chunk 3/10... Label: 1\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 1\n",
      "  Chunk 7/10... Label: 1\n",
      "  Chunk 8/10... Label: 1\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q4/20: How does TCS BaNCS support banking opera...\n",
      "  Chunk 1/10... Label: 0\n",
      "  Chunk 2/10... Label: 1\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 1\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q5/20: What capabilities does TCS Crystallus of...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 0\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q6/20: How does TCS OptumeraTM enhance retail o...\n",
      "  Chunk 1/10... Label: 0\n",
      "  Chunk 2/10... Label: 0\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q7/20: What is the purpose of TCS OmniStore pla...\n",
      "  Chunk 1/10... Label: 0\n",
      "  Chunk 2/10... Label: 0\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q8/20: How does TCS ignioTM transform IT operat...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 0\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 1\n",
      "\n",
      "Labeling Q9/20: What role does TCS Clever Energy play in...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 0\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 1\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 1\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 1\n",
      "  Chunk 9/10... Label: 1\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q10/20: How does TCS MasterCraft support softwar...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 1\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 1\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q11/20: What is the function of TCS TwinX in dig...\n",
      "  Chunk 1/10... Label: 0\n",
      "  Chunk 2/10... Label: 0\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q12/20: How does TCS InTwin enable simulable ent...\n",
      "  Chunk 1/10... Label: 0\n",
      "  Chunk 2/10... Label: 0\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q13/20: What services does TCS iON provide for l...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 0\n",
      "  Chunk 3/10... Label: 1\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q14/20: How does TCS ADD platform support clinic...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 1\n",
      "  Chunk 3/10... Label: 1\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q15/20: What is the impact of TCS CodeVita progr...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 1\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q16/20: How does TCS Bringing Life to Things Lab...\n",
      "  Chunk 1/10... Label: 0\n",
      "  Chunk 2/10... Label: 1\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 1\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q17/20: What is the significance of TCS Quantum ...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 1\n",
      "  Chunk 3/10... Label: 1\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q18/20: How does TCS support the National Quantu...\n",
      "  Chunk 1/10... Label: 0\n",
      "  Chunk 2/10... Label: 1\n",
      "  Chunk 3/10... Label: 1\n",
      "  Chunk 4/10... Label: 0\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 1\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q19/20: What role does TCS Pace Studio play in r...\n",
      "  Chunk 1/10... Label: 1\n",
      "  Chunk 2/10... Label: 1\n",
      "  Chunk 3/10... Label: 0\n",
      "  Chunk 4/10... Label: 1\n",
      "  Chunk 5/10... Label: 1\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "Labeling Q20/20: How does TCS All-women Digital Services ...\n",
      "  Chunk 1/10... Label: 0\n",
      "  Chunk 2/10... Label: 0\n",
      "  Chunk 3/10... Label: 1\n",
      "  Chunk 4/10... Label: 1\n",
      "  Chunk 5/10... Label: 0\n",
      "  Chunk 6/10... Label: 0\n",
      "  Chunk 7/10... Label: 0\n",
      "  Chunk 8/10... Label: 0\n",
      "  Chunk 9/10... Label: 0\n",
      "  Chunk 10/10... Label: 0\n",
      "\n",
      "‚úÖ Labeling complete!\n",
      "üìä Total labeled pairs: 200\n",
      "üìà Label distribution:\n",
      "   Relevant (1): 47 (23.5%)\n",
      "   Irrelevant (0): 153 (76.5%)\n",
      "\n",
      "üéØ Training data ready for adaptor matrix training!\n"
     ]
    }
   ],
   "source": [
    "# Label Relevance with GPT-4.1\n",
    "def label_relevance(question, chunk):\n",
    "    \"\"\"Use GPT-4.1 to label (question, chunk) pair relevance\"\"\"\n",
    "    prompt = f\"\"\"You are evaluating document chunk relevance for a TCS Annual Report question.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Document Chunk: {chunk}\n",
    "\n",
    "Is this chunk relevant to answering the question?\n",
    "- Reply \"1\" if the chunk contains information that helps answer the question\n",
    "- Reply \"0\" if the chunk is not relevant or doesn't help answer the question\n",
    "\n",
    "Only respond with \"1\" or \"0\".\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            input=prompt\n",
    "        )\n",
    "        \n",
    "        # Extract response\n",
    "        content = response.output_text.strip()\n",
    "        \n",
    "        # Parse label\n",
    "        if content == \"1\":\n",
    "            return 1\n",
    "        elif content == \"0\":\n",
    "            return 0\n",
    "        else:\n",
    "            # Fallback parsing\n",
    "            if \"1\" in content:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error labeling relevance: {e}\")\n",
    "        return 0  # Default to not relevant\n",
    "\n",
    "print(\"ü§ñ Starting relevance labeling with GPT-4.1...\")\n",
    "print(\"This will take a few minutes...\")\n",
    "\n",
    "# Create labeled training dataset\n",
    "labeled_training_data = []\n",
    "\n",
    "for q_idx, question_data in enumerate(training_data_raw, 1):\n",
    "    question = question_data['question']\n",
    "    print(f\"\\nLabeling Q{q_idx}/20: {question[:40]}...\")\n",
    "    \n",
    "    for chunk_idx, chunk in enumerate(question_data['chunks'], 1):\n",
    "        print(f\"  Chunk {chunk_idx}/10...\", end=\"\")\n",
    "        \n",
    "        # Get relevance label\n",
    "        label = label_relevance(question, chunk)\n",
    "        \n",
    "        # Store labeled pair\n",
    "        labeled_training_data.append({\n",
    "            'question': question,\n",
    "            'chunk': chunk,\n",
    "            'label': label,\n",
    "            'distance': question_data['distances'][chunk_idx-1],\n",
    "            'chunk_id': question_data['ids'][chunk_idx-1]\n",
    "        })\n",
    "        \n",
    "        print(f\" Label: {label}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Labeling complete!\")\n",
    "print(f\"üìä Total labeled pairs: {len(labeled_training_data)}\")\n",
    "\n",
    "# Show label distribution\n",
    "relevant_count = sum(1 for item in labeled_training_data if item['label'] == 1)\n",
    "irrelevant_count = len(labeled_training_data) - relevant_count\n",
    "\n",
    "print(f\"üìà Label distribution:\")\n",
    "print(f\"   Relevant (1): {relevant_count} ({relevant_count/len(labeled_training_data)*100:.1f}%)\")\n",
    "print(f\"   Irrelevant (0): {irrelevant_count} ({irrelevant_count/len(labeled_training_data)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüéØ Training data ready for adaptor matrix training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-header",
   "metadata": {},
   "source": [
    "# Step 3: Train Simple Adaptor Matrix\n",
    "\n",
    "Now we'll train a 384√ó384 transformation matrix to adapt query embeddings.\n",
    "\n",
    "**Goal**: Learn `adapted_query = matrix √ó original_query` that improves cosine similarity with relevant chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prepare-embeddings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Preparing embeddings for training...\n",
      "Generating embeddings for 20 questions...\n",
      "Generating embeddings for 200 chunks...\n",
      "‚úÖ Embeddings ready:\n",
      "   Question embeddings: (20, 384)\n",
      "   Chunk embeddings: (200, 384)\n",
      "   Embedding dimension: 384\n",
      "\n",
      "üéØ Training pairs ready: 200\n",
      "Ready for matrix training!\n"
     ]
    }
   ],
   "source": [
    "# Prepare Embeddings for Training\n",
    "print(\"üî¢ Preparing embeddings for training...\")\n",
    "\n",
    "# Get unique questions and chunks\n",
    "unique_questions = list(set(item['question'] for item in labeled_training_data))\n",
    "all_chunks = [item['chunk'] for item in labeled_training_data]\n",
    "\n",
    "print(f\"Generating embeddings for {len(unique_questions)} questions...\")\n",
    "question_embeddings = embedding_model.encode(unique_questions)\n",
    "\n",
    "print(f\"Generating embeddings for {len(all_chunks)} chunks...\")\n",
    "chunk_embeddings = embedding_model.encode(all_chunks)\n",
    "\n",
    "# Create mapping from question to embedding\n",
    "question_to_embedding = {q: emb for q, emb in zip(unique_questions, question_embeddings)}\n",
    "\n",
    "print(f\"‚úÖ Embeddings ready:\")\n",
    "print(f\"   Question embeddings: {question_embeddings.shape}\")\n",
    "print(f\"   Chunk embeddings: {chunk_embeddings.shape}\")\n",
    "print(f\"   Embedding dimension: {question_embeddings.shape[1]}\")\n",
    "\n",
    "# Prepare training data\n",
    "training_pairs = []\n",
    "\n",
    "for i, item in enumerate(labeled_training_data):\n",
    "    question_emb = question_to_embedding[item['question']]\n",
    "    chunk_emb = chunk_embeddings[i]\n",
    "    label = item['label']\n",
    "    \n",
    "    training_pairs.append({\n",
    "        'question_emb': question_emb,\n",
    "        'chunk_emb': chunk_emb,\n",
    "        'label': label\n",
    "    })\n",
    "\n",
    "print(f\"\\nüéØ Training pairs ready: {len(training_pairs)}\")\n",
    "print(\"Ready for matrix training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "train-adaptor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Adaptor Matrix initialized: 384√ó384\n",
      "üìä Parameters: 147,456\n",
      "\n",
      "üîÑ Starting training...\n",
      "Training data: 200 pairs\n",
      "Epoch 20/100, Loss: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Local\\Temp\\ipykernel_32828\\245956038.py:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  question_tensors = torch.FloatTensor([pair['question_emb'] for pair in training_pairs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.0536\n",
      "Epoch 60/100, Loss: 0.0467\n",
      "Epoch 80/100, Loss: 0.0442\n",
      "Epoch 100/100, Loss: 0.0432\n",
      "\n",
      "‚úÖ Training complete!\n",
      "üìâ Final loss: 0.0432\n",
      "üìà Loss improvement: 0.2251 ‚Üí 0.0432\n",
      "üíæ Adaptor matrix saved to: tcs_adaptor_matrix.pth\n",
      "\n",
      "üéØ Adaptor matrix training complete! Ready for testing.\n"
     ]
    }
   ],
   "source": [
    "# Train Adaptor Matrix\n",
    "class AdaptorMatrix(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(AdaptorMatrix, self).__init__()\n",
    "        # Initialize transformation matrix\n",
    "        self.transform = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "        \n",
    "        # Initialize weights (start close to identity)\n",
    "        nn.init.eye_(self.transform.weight)\n",
    "        \n",
    "    def forward(self, query_embeddings):\n",
    "        # Apply transformation\n",
    "        return self.transform(query_embeddings)\n",
    "\n",
    "# Setup training\n",
    "embedding_dim = question_embeddings.shape[1]\n",
    "adaptor = AdaptorMatrix(embedding_dim)\n",
    "optimizer = optim.Adam(adaptor.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(f\"ü§ñ Adaptor Matrix initialized: {embedding_dim}√ó{embedding_dim}\")\n",
    "print(f\"üìä Parameters: {sum(p.numel() for p in adaptor.parameters()):,}\")\n",
    "\n",
    "# Convert to tensors\n",
    "question_tensors = torch.FloatTensor([pair['question_emb'] for pair in training_pairs])\n",
    "chunk_tensors = torch.FloatTensor([pair['chunk_emb'] for pair in training_pairs])\n",
    "label_tensors = torch.FloatTensor([pair['label'] for pair in training_pairs])\n",
    "\n",
    "print(f\"\\nüîÑ Starting training...\")\n",
    "print(f\"Training data: {len(training_pairs)} pairs\")\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    adapted_questions = adaptor(question_tensors)\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    similarities = torch.sum(adapted_questions * chunk_tensors, dim=1) / (\n",
    "        torch.norm(adapted_questions, dim=1) * torch.norm(chunk_tensors, dim=1)\n",
    "    )\n",
    "    \n",
    "    # Loss: MSE between similarity and labels\n",
    "    loss = criterion(similarities, label_tensors)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete!\")\n",
    "print(f\"üìâ Final loss: {losses[-1]:.4f}\")\n",
    "print(f\"üìà Loss improvement: {losses[0]:.4f} ‚Üí {losses[-1]:.4f}\")\n",
    "\n",
    "# Save the trained adaptor\n",
    "torch.save(adaptor.state_dict(), 'tcs_adaptor_matrix.pth')\n",
    "print(f\"üíæ Adaptor matrix saved to: tcs_adaptor_matrix.pth\")\n",
    "\n",
    "print(\"\\nüéØ Adaptor matrix training complete! Ready for testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-header",
   "metadata": {},
   "source": [
    "# Step 4: Compare Simple RAG vs Adapted RAG\n",
    "\n",
    "Now we'll test both approaches on our 20 test questions and see which performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "implement-rag-functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG functions implemented\n",
      "   ‚Ä¢ simple_rag: Standard retrieval\n",
      "   ‚Ä¢ adapted_rag: Uses trained adaptor matrix\n",
      "\n",
      "üéØ Ready to test on 20 questions!\n"
     ]
    }
   ],
   "source": [
    "# Implement RAG Functions\n",
    "def simple_rag(question, collection, client, n_chunks=3):\n",
    "    \"\"\"Standard RAG with original embeddings\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Retrieve chunks\n",
    "    results = collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=n_chunks\n",
    "    )\n",
    "    \n",
    "    chunks = results['documents'][0]\n",
    "    context = \"\\n\\n\".join(chunks)\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Based on the TCS Annual Report information below, answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer based only on the provided context:\"\"\"\n",
    "    \n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=prompt\n",
    "    )\n",
    "    \n",
    "    runtime = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        'answer': response.output_text,\n",
    "        'chunks': chunks,\n",
    "        'runtime': round(runtime, 1)\n",
    "    }\n",
    "\n",
    "def adapted_rag(question, collection, client, adaptor_model, embedding_model, n_chunks=3):\n",
    "    \"\"\"RAG with adapted query embeddings\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get original query embedding\n",
    "    original_embedding = embedding_model.encode([question])[0]\n",
    "    \n",
    "    # Apply adaptor transformation\n",
    "    with torch.no_grad():\n",
    "        original_tensor = torch.FloatTensor(original_embedding).unsqueeze(0)\n",
    "        adapted_tensor = adaptor_model(original_tensor)\n",
    "        adapted_embedding = adapted_tensor.squeeze(0).numpy()\n",
    "    \n",
    "    # Get all document embeddings from ChromaDB for similarity search\n",
    "    all_results = collection.get(\n",
    "        include=[\"embeddings\", \"documents\"]\n",
    "    )\n",
    "    \n",
    "    doc_embeddings = np.array(all_results['embeddings'])\n",
    "    \n",
    "    # Calculate similarities with adapted query\n",
    "    similarities = cosine_similarity([adapted_embedding], doc_embeddings)[0]\n",
    "    \n",
    "    # Get top chunks\n",
    "    top_indices = np.argsort(similarities)[::-1][:n_chunks]\n",
    "    chunks = [all_results['documents'][i] for i in top_indices]\n",
    "    \n",
    "    context = \"\\n\\n\".join(chunks)\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Based on the TCS Annual Report information below, answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer based only on the provided context:\"\"\"\n",
    "    \n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=prompt\n",
    "    )\n",
    "    \n",
    "    runtime = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        'answer': response.output_text,\n",
    "        'chunks': chunks,\n",
    "        'runtime': round(runtime, 1)\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ RAG functions implemented\")\n",
    "print(\"   ‚Ä¢ simple_rag: Standard retrieval\")\n",
    "print(\"   ‚Ä¢ adapted_rag: Uses trained adaptor matrix\")\n",
    "print(\"\\nüéØ Ready to test on 20 questions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "run-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ TESTING: Simple RAG vs Adapted RAG\n",
      "==================================================\n",
      "\n",
      "Testing Q1/20: What are TCS's main research and development priorities?...\n",
      "  üîÑ Simple RAG... ‚úÖ (7.0s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (3.5s)\n",
      "\n",
      "Testing Q2/20: How does TCS approach digital transformation for manufacturi...\n",
      "  üîÑ Simple RAG... ‚úÖ (5.2s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (6.4s)\n",
      "\n",
      "Testing Q3/20: What is TCS's strategy for artificial intelligence implement...\n",
      "  üîÑ Simple RAG... ‚úÖ (6.9s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (9.3s)\n",
      "\n",
      "Testing Q4/20: How does TCS support clients in cloud migration initiatives?...\n",
      "  üîÑ Simple RAG... ‚úÖ (6.8s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (7.5s)\n",
      "\n",
      "Testing Q5/20: What role does TCS play in cybersecurity solutions?...\n",
      "  üîÑ Simple RAG... ‚úÖ (3.3s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (3.6s)\n",
      "\n",
      "Testing Q6/20: How does TCS contribute to sustainability and green energy i...\n",
      "  üîÑ Simple RAG... ‚úÖ (6.0s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (5.9s)\n",
      "\n",
      "Testing Q7/20: What is TCS's approach to talent development and reskilling?...\n",
      "  üîÑ Simple RAG... ‚úÖ (4.0s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (5.0s)\n",
      "\n",
      "Testing Q8/20: How does TCS support government digital transformation proje...\n",
      "  üîÑ Simple RAG... ‚úÖ (5.7s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (7.5s)\n",
      "\n",
      "Testing Q9/20: What are TCS's key partnerships with technology vendors?...\n",
      "  üîÑ Simple RAG... ‚úÖ (3.4s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (3.1s)\n",
      "\n",
      "Testing Q10/20: How does TCS approach innovation in financial services?...\n",
      "  üîÑ Simple RAG... ‚úÖ (4.6s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (4.0s)\n",
      "\n",
      "Testing Q11/20: What is TCS's methodology for enterprise modernization?...\n",
      "  üîÑ Simple RAG... ‚úÖ (2.1s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (7.2s)\n",
      "\n",
      "Testing Q12/20: How does TCS support healthcare and life sciences digitizati...\n",
      "  üîÑ Simple RAG... ‚úÖ (3.7s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (6.0s)\n",
      "\n",
      "Testing Q13/20: What are TCS's capabilities in data analytics and insights?...\n",
      "  üîÑ Simple RAG... ‚úÖ (4.4s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (5.3s)\n",
      "\n",
      "Testing Q14/20: How does TCS approach automation in business operations?...\n",
      "  üîÑ Simple RAG... ‚úÖ (4.7s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (8.1s)\n",
      "\n",
      "Testing Q15/20: What role does TCS play in telecommunications modernization?...\n",
      "  üîÑ Simple RAG... ‚úÖ (2.8s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (2.6s)\n",
      "\n",
      "Testing Q16/20: How does TCS support retail and consumer business transforma...\n",
      "  üîÑ Simple RAG... ‚úÖ (9.2s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (4.1s)\n",
      "\n",
      "Testing Q17/20: What is TCS's approach to regulatory compliance solutions?...\n",
      "  üîÑ Simple RAG... ‚úÖ (4.2s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (3.4s)\n",
      "\n",
      "Testing Q18/20: How does TCS enable supply chain optimization for clients?...\n",
      "  üîÑ Simple RAG... ‚úÖ (3.4s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (4.1s)\n",
      "\n",
      "Testing Q19/20: What are TCS's key differentiators in the IT services market...\n",
      "  üîÑ Simple RAG... ‚úÖ (11.3s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (6.6s)\n",
      "\n",
      "Testing Q20/20: How does TCS measure and ensure client satisfaction?...\n",
      "  üîÑ Simple RAG... ‚úÖ (4.3s)\n",
      "  üîÑ Adapted RAG... ‚úÖ (4.3s)\n",
      "\n",
      "‚úÖ Comparison testing complete!\n",
      "üìä Tested 20 questions\n",
      "‚è±Ô∏è  Average Simple RAG time: 5.2s\n",
      "‚è±Ô∏è  Average Adapted RAG time: 5.4s\n",
      "\n",
      "üéØ Ready for judge evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Run Comparison Test\n",
    "print(\"üî¨ TESTING: Simple RAG vs Adapted RAG\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nTesting Q{i}/20: {question[:60]}...\")\n",
    "    \n",
    "    try:\n",
    "        # Test Simple RAG\n",
    "        print(\"  üîÑ Simple RAG...\", end=\"\")\n",
    "        simple_result = simple_rag(question, chroma_collection, client)\n",
    "        print(f\" ‚úÖ ({simple_result['runtime']}s)\")\n",
    "        \n",
    "        # Test Adapted RAG\n",
    "        print(\"  üîÑ Adapted RAG...\", end=\"\")\n",
    "        adapted_result = adapted_rag(question, chroma_collection, client, adaptor, embedding_model)\n",
    "        print(f\" ‚úÖ ({adapted_result['runtime']}s)\")\n",
    "        \n",
    "        # Store results\n",
    "        comparison_results.append({\n",
    "            'question_id': i,\n",
    "            'question': question,\n",
    "            'simple_answer': simple_result['answer'],\n",
    "            'simple_chunks': simple_result['chunks'],\n",
    "            'simple_time': simple_result['runtime'],\n",
    "            'adapted_answer': adapted_result['answer'],\n",
    "            'adapted_chunks': adapted_result['chunks'],\n",
    "            'adapted_time': adapted_result['runtime']\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" ‚ùå Error: {e}\")\n",
    "        comparison_results.append({\n",
    "            'question_id': i,\n",
    "            'question': question,\n",
    "            'simple_answer': f\"Error: {e}\",\n",
    "            'simple_chunks': [],\n",
    "            'simple_time': 0,\n",
    "            'adapted_answer': f\"Error: {e}\",\n",
    "            'adapted_chunks': [],\n",
    "            'adapted_time': 0\n",
    "        })\n",
    "\n",
    "print(f\"\\n‚úÖ Comparison testing complete!\")\n",
    "print(f\"üìä Tested {len(comparison_results)} questions\")\n",
    "print(f\"‚è±Ô∏è  Average Simple RAG time: {np.mean([r['simple_time'] for r in comparison_results if r['simple_time'] > 0]):.1f}s\")\n",
    "print(f\"‚è±Ô∏è  Average Adapted RAG time: {np.mean([r['adapted_time'] for r in comparison_results if r['adapted_time'] > 0]):.1f}s\")\n",
    "\n",
    "print(\"\\nüéØ Ready for judge evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "judge-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Starting judge evaluation...\n",
      "This will take a few minutes...\n",
      "Judging Q1/20: What are TCS's main research and develop... A\n",
      "Judging Q2/20: How does TCS approach digital transforma... B\n",
      "Judging Q3/20: What is TCS's strategy for artificial in... B\n",
      "Judging Q4/20: How does TCS support clients in cloud mi... B\n",
      "Judging Q5/20: What role does TCS play in cybersecurity... B\n",
      "Judging Q6/20: How does TCS contribute to sustainabilit... B\n",
      "Judging Q7/20: What is TCS's approach to talent develop... A\n",
      "Judging Q8/20: How does TCS support government digital ... A\n",
      "Judging Q9/20: What are TCS's key partnerships with tec... A\n",
      "Judging Q10/20: How does TCS approach innovation in fina... B\n",
      "Judging Q11/20: What is TCS's methodology for enterprise... B\n",
      "Judging Q12/20: How does TCS support healthcare and life... B\n",
      "Judging Q13/20: What are TCS's capabilities in data anal... B\n",
      "Judging Q14/20: How does TCS approach automation in busi... B\n",
      "Judging Q15/20: What role does TCS play in telecommunica... B\n",
      "Judging Q16/20: How does TCS support retail and consumer... B\n",
      "Judging Q17/20: What is TCS's approach to regulatory com... A\n",
      "Judging Q18/20: How does TCS enable supply chain optimiz... B\n",
      "Judging Q19/20: What are TCS's key differentiators in th... B\n",
      "Judging Q20/20: How does TCS measure and ensure client s... B\n",
      "\n",
      "‚úÖ Judge evaluation complete!\n",
      "\n",
      "üèÜ JUDGE RESULTS:\n",
      "   Simple RAG wins: 5/20\n",
      "   Adapted RAG wins: 15/20\n",
      "   Ties: 0/20\n",
      "\n",
      "üéØ Ready for final analysis!\n"
     ]
    }
   ],
   "source": [
    "# Judge Evaluation: Which RAG approach is better?\n",
    "def judge_comparison(question, simple_answer, adapted_answer):\n",
    "    \"\"\"Use GPT-4.1 to judge which answer is better\"\"\"\n",
    "    prompt = f\"\"\"Compare these two answers to a TCS Annual Report question.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer A (Simple RAG): {simple_answer}\n",
    "\n",
    "Answer B (Adapted RAG): {adapted_answer}\n",
    "\n",
    "Which answer is better? Consider accuracy, completeness, and relevance.\n",
    "Respond with exactly one of:\n",
    "- \"A\" if Answer A is better\n",
    "- \"B\" if Answer B is better  \n",
    "- \"TIE\" if both answers are equally good\n",
    "\n",
    "Only respond with A, B, or TIE.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            input=prompt\n",
    "        )\n",
    "        \n",
    "        result = response.output_text.strip().upper()\n",
    "        \n",
    "        if result in ['A', 'B', 'TIE']:\n",
    "            return result\n",
    "        else:\n",
    "            # Fallback parsing\n",
    "            if 'A' in result and 'B' not in result:\n",
    "                return 'A'\n",
    "            elif 'B' in result and 'A' not in result:\n",
    "                return 'B'\n",
    "            else:\n",
    "                return 'TIE'\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Judge error: {e}\")\n",
    "        return 'TIE'\n",
    "\n",
    "print(\"ü§ñ Starting judge evaluation...\")\n",
    "print(\"This will take a few minutes...\")\n",
    "\n",
    "# Evaluate each comparison\n",
    "for i, result in enumerate(comparison_results, 1):\n",
    "    question = result['question']\n",
    "    simple_answer = result['simple_answer']\n",
    "    adapted_answer = result['adapted_answer']\n",
    "    \n",
    "    print(f\"Judging Q{i}/20: {question[:40]}...\", end=\"\")\n",
    "    \n",
    "    judgment = judge_comparison(question, simple_answer, adapted_answer)\n",
    "    comparison_results[i-1]['judgment'] = judgment\n",
    "    \n",
    "    print(f\" {judgment}\")\n",
    "\n",
    "print(\"\\n‚úÖ Judge evaluation complete!\")\n",
    "\n",
    "# Calculate results\n",
    "judgments = [r['judgment'] for r in comparison_results]\n",
    "simple_wins = judgments.count('A')\n",
    "adapted_wins = judgments.count('B')\n",
    "ties = judgments.count('TIE')\n",
    "\n",
    "print(f\"\\nüèÜ JUDGE RESULTS:\")\n",
    "print(f\"   Simple RAG wins: {simple_wins}/{len(judgments)}\")\n",
    "print(f\"   Adapted RAG wins: {adapted_wins}/{len(judgments)}\")\n",
    "print(f\"   Ties: {ties}/{len(judgments)}\")\n",
    "\n",
    "print(\"\\nüéØ Ready for final analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5-header",
   "metadata": {},
   "source": [
    "# Step 5: Analysis and Learning Insights\n",
    "\n",
    "Let's analyze what we learned from this embedding adaptation experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "final-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä EMBEDDING ADAPTOR EXPERIMENT - FINAL ANALYSIS\n",
      "============================================================\n",
      "\n",
      "üèÜ OVERALL RESULTS:\n",
      "------------------------------\n",
      "Total questions tested: 20\n",
      "Simple RAG wins: 5 (25.0%)\n",
      "Adapted RAG wins: 15 (75.0%)\n",
      "Ties: 0 (0.0%)\n",
      "\n",
      "üèÖ Winner: Adapted RAG\n",
      "   Advantage: +10 questions (50.0%)\n",
      "\n",
      "‚è±Ô∏è  SPEED ANALYSIS:\n",
      "   Simple RAG avg time: 5.2s\n",
      "   Adapted RAG avg time: 5.4s\n",
      "   Speed difference: +4.4%\n",
      "\n",
      "üìà TRAINING DATA INSIGHTS:\n",
      "   Training pairs used: 200\n",
      "   Relevant pairs: 47 (23.5%)\n",
      "   Matrix parameters: 147,456\n",
      "   Training epochs: 100\n",
      "   Final training loss: 0.0432\n",
      "\n",
      "üí° KEY LEARNING INSIGHTS:\n",
      "------------------------------\n",
      "‚úÖ Domain adaptation HELPED:\n",
      "   ‚Ä¢ Adapted RAG won 15/20 comparisons\n",
      "   ‚Ä¢ The matrix learned useful TCS-specific transformations\n",
      "   ‚Ä¢ Parameter-efficient adaptation can improve retrieval\n",
      "\n",
      "üéØ METHODOLOGY LEARNINGS:\n",
      "   ‚Ä¢ Successfully implemented parameter-efficient embedding adaptation\n",
      "   ‚Ä¢ GPT-4.1 labeling created realistic training data\n",
      "   ‚Ä¢ Matrix training converged (loss: 0.2251 ‚Üí 0.0432)\n",
      "   ‚Ä¢ End-to-end evaluation pipeline worked\n",
      "\n",
      "üîç WHAT THIS TEACHES US:\n",
      "   ‚Ä¢ Embedding spaces can be adapted with simple transformations\n",
      "   ‚Ä¢ Domain-specific improvements require careful evaluation\n",
      "   ‚Ä¢ Parameter efficiency: 147k params vs full model retraining\n",
      "   ‚Ä¢ Real-world adaptation benefits depend on domain gap\n",
      "\n",
      "üíæ Results saved to: embedding_adaptor_results_20250929_153212.csv\n",
      "\n",
      "üéâ EMBEDDING ADAPTOR EXPERIMENT COMPLETE!\n",
      "üéì You've successfully learned about domain-specific embedding adaptation!\n"
     ]
    }
   ],
   "source": [
    "# Final Analysis and Learning Insights\n",
    "print(\"üìä EMBEDDING ADAPTOR EXPERIMENT - FINAL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create results DataFrame\n",
    "df_results = pd.DataFrame(comparison_results)\n",
    "\n",
    "# Overall Performance Summary\n",
    "print(\"\\nüèÜ OVERALL RESULTS:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Total questions tested: {len(comparison_results)}\")\n",
    "print(f\"Simple RAG wins: {simple_wins} ({simple_wins/len(judgments)*100:.1f}%)\")\n",
    "print(f\"Adapted RAG wins: {adapted_wins} ({adapted_wins/len(judgments)*100:.1f}%)\")\n",
    "print(f\"Ties: {ties} ({ties/len(judgments)*100:.1f}%)\")\n",
    "\n",
    "# Performance Analysis\n",
    "if adapted_wins > simple_wins:\n",
    "    winner = \"Adapted RAG\"\n",
    "    improvement = adapted_wins - simple_wins\n",
    "elif simple_wins > adapted_wins:\n",
    "    winner = \"Simple RAG\"\n",
    "    improvement = simple_wins - adapted_wins\n",
    "else:\n",
    "    winner = \"TIE\"\n",
    "    improvement = 0\n",
    "\n",
    "print(f\"\\nüèÖ Winner: {winner}\")\n",
    "if improvement > 0:\n",
    "    print(f\"   Advantage: +{improvement} questions ({improvement/len(judgments)*100:.1f}%)\")\n",
    "\n",
    "# Speed Analysis\n",
    "avg_simple_time = np.mean([r['simple_time'] for r in comparison_results if r['simple_time'] > 0])\n",
    "avg_adapted_time = np.mean([r['adapted_time'] for r in comparison_results if r['adapted_time'] > 0])\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  SPEED ANALYSIS:\")\n",
    "print(f\"   Simple RAG avg time: {avg_simple_time:.1f}s\")\n",
    "print(f\"   Adapted RAG avg time: {avg_adapted_time:.1f}s\")\n",
    "print(f\"   Speed difference: {((avg_adapted_time - avg_simple_time)/avg_simple_time*100):+.1f}%\")\n",
    "\n",
    "# Training Data Analysis\n",
    "print(f\"\\nüìà TRAINING DATA INSIGHTS:\")\n",
    "print(f\"   Training pairs used: {len(labeled_training_data)}\")\n",
    "print(f\"   Relevant pairs: {relevant_count} ({relevant_count/len(labeled_training_data)*100:.1f}%)\")\n",
    "print(f\"   Matrix parameters: {sum(p.numel() for p in adaptor.parameters()):,}\")\n",
    "print(f\"   Training epochs: {num_epochs}\")\n",
    "print(f\"   Final training loss: {losses[-1]:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° KEY LEARNING INSIGHTS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if adapted_wins > simple_wins:\n",
    "    print(\"‚úÖ Domain adaptation HELPED:\")\n",
    "    print(f\"   ‚Ä¢ Adapted RAG won {adapted_wins}/{len(judgments)} comparisons\")\n",
    "    print(\"   ‚Ä¢ The matrix learned useful TCS-specific transformations\")\n",
    "    print(\"   ‚Ä¢ Parameter-efficient adaptation can improve retrieval\")\n",
    "else:\n",
    "    print(\"‚ùì Domain adaptation had MIXED results:\")\n",
    "    print(f\"   ‚Ä¢ Simple RAG still won {simple_wins}/{len(judgments)} comparisons\")\n",
    "    print(\"   ‚Ä¢ General embeddings may already capture TCS concepts well\")\n",
    "    print(\"   ‚Ä¢ More training data or different architecture might help\")\n",
    "\n",
    "print(f\"\\nüéØ METHODOLOGY LEARNINGS:\")\n",
    "print(\"   ‚Ä¢ Successfully implemented parameter-efficient embedding adaptation\")\n",
    "print(\"   ‚Ä¢ GPT-4.1 labeling created realistic training data\")\n",
    "print(f\"   ‚Ä¢ Matrix training converged (loss: {losses[0]:.4f} ‚Üí {losses[-1]:.4f})\")\n",
    "print(\"   ‚Ä¢ End-to-end evaluation pipeline worked\")\n",
    "\n",
    "print(f\"\\nüîç WHAT THIS TEACHES US:\")\n",
    "print(\"   ‚Ä¢ Embedding spaces can be adapted with simple transformations\")\n",
    "print(\"   ‚Ä¢ Domain-specific improvements require careful evaluation\")\n",
    "print(\"   ‚Ä¢ Parameter efficiency: 147k params vs full model retraining\")\n",
    "print(\"   ‚Ä¢ Real-world adaptation benefits depend on domain gap\")\n",
    "\n",
    "# Save results\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_file = f\"embedding_adaptor_results_{timestamp}.csv\"\n",
    "df_results.to_csv(results_file, index=False)\n",
    "print(f\"\\nüíæ Results saved to: {results_file}\")\n",
    "\n",
    "print(f\"\\nüéâ EMBEDDING ADAPTOR EXPERIMENT COMPLETE!\")\n",
    "print(\"üéì You've successfully learned about domain-specific embedding adaptation!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "25September2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
